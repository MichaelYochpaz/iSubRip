# ---------------- ⚠️ IMPORTANT - READ BEFORE USING ⚠️ ----------------
# This is an example config file with all available settings and their default values (if they have one).
# All settings are optional, and setting them in the config file will override their default values.
#
# In your config file, set only settings you wish to change from their default values.
# Do NOT copy this file and use it as your config, as it will override ALL settings with the values specified here.
# Use this file only as a reference to understand what different settings do,
# and to decide which settings you should use in your config.
#
# Your config file should be saved in the following path (according to OS):
#   - Windows: %USERPROFILE%\.isubrip\config.toml
#   - Linux / macOS: $HOME/.isubrip/config.toml
# ---------------------------------------------------------------------

[general]
# Check for updates before running, and show a note if a new version exists.
# Value can be either 'true' or 'false'.
check-for-updates = true

# Maximum number of log files to keep in the logs folder.
# Once the maximum number is reached, the oldest logs files will be deleted in rotation
# until the number of files equals the maximum.
log-rotation-size = 15

# Log level to use for stdout (console) output.
# Value can be one of: "debug", "info", "error", "warning", "critical".
log-level = "info"


[downloads]
# Folder to downloads files to.
# The default "." value means it will download to the same folder the script ran from.
# Use double backslashes in path to avoid escaping characters. Example: "C:\\Users\\<username>\\Downloads\\"
folder = "."

# A list of iTunes language codes to download.
# An empty array (like the one currently being used) will result in downloading all of the available subtitles.
# Example: ["en-US", "fr-FR", "he"]
languages = []

# Whether to overwrite existing subtitles files.
# If set to false, names of existing subtitles will have a number appended to them to avoid overwriting.
# Value can be either 'true' or 'false'.
overwrite-existing = false

# Save files into a zip archive if there is more than one matching subtitles.
# Value can be either 'true' or 'false'.
zip = false


[subtitles]
# Fix RTL for RTL languages (Arabic & Hebrew).
# Value can be either 'true' or 'false'.
#
# NOTE: This is off by default as some subtitles use other methods to fix RTL (like writing punctuations backwards).
#       Using this option on these type of subtitles can break the already-fixed RTL issues.
fix-rtl = false

# Remove duplicate paragraphs (same text and timestamps).
# Value can be either 'true' or 'false'.
remove-duplicates = true

# Whether to convert subtitles to SRT format.
# NOTE: This can cause loss of subtitles metadata that is not supported by SRT format.
convert-to-srt = false

[subtitles.webvtt]
# Whether to add a '{\an8}' tag to lines that are aligned at the top when converting format from WebVTT to SubRip.
# Relevant only if 'subtitles.convert-to-srt' is set to 'true'.
# Value can be either 'true' or 'false'.
subrip-alignment-conversion = false


[scrapers.default]
# A subcategory to set default values for all scrapers.
# These settings will be overridden by scraper-specific configuration, if set,
# These settings will not apply if the scraper has a different specific default value.

# Timeout in seconds for requests sent by all scrapers.
timeout = 10

# User-Agent to use by default for requests sent by all scrapers.
user-agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36"

# Proxy to use by default for requests sent by all scrapers.
proxy = "http://127.0.0.1:8080"

# Whether to verify SSL certificates when making requests for all scrapers.
# Value can be either 'true' or 'false'.
verify-ssl = true


[scrapers.scraper-name]
# Scraper-specific settings (set for each scraper separately).
# Will override any default values previously set.
# Replace 'scraper-name' with the name of the scraper to configure.
# Available scrapers: itunes, appletv

# Timeout in seconds for requests sent by the scraper.
timeout = 10

# User-Agent to use for requests sent by the scraper.
user-agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36"

# Proxy to use for requests sent by the scraper.
proxy = "http://127.0.0.1:8080"

# Whether to verify SSL certificates when making requests for the scraper.
# Value can be either 'true' or 'false'.
verify-ssl = true
